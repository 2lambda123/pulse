NOTES:
 *	detectionInterval {number} : time we wait before doing a new facedetection (default is 20 ms)
 *	fadeVideo {boolean} : whether to fade out video when face is detected (default is false)

 Headtrackr.js
 headtrackr.Tracker:
 1. determines if the user has set any paramaters, if not, sets defaults
 	1a. defines the ui, smoother, facetracker, headposition, canvasContext, videoElement, and detector
 	1b. creates a statusEvent in the document for headtrackrStatus
 	1c. headtrackrStatus is used in ui to write the message of what's happening
 2. initializes the video and camera, brings in webcam to browser, creates canvas, canvas overlay, and video elements
 	2a. adds a listener for "playing" to resize video
 	2b. adds ui
 	2c. adds smoother
 	2d. sets "this.initialized" status to True
 3. track = function() -- drawsImage on the canvasContext
 	3a. if no facetracking, it initializes facetracker and creates new facetracker object (facetracker = new headtracker.facetrackr.Tracker with parameters, then initializes in canvas)
 	3b. tracks face w/ facetracker.track and creates a 'face' object with .getTrackingObject
 	3c. determines which algorithm the faceobj is using to find face, sets the headtrackerstatus (wB == whitebalance, firstRun + detection + VJ == detecting)
 	3d. looks at the confidence and runs some tests re: timing if the confidence is 0, if it's 0 AND detection == CS, find the midpoint of the faceobject and draw face on debugger canvas
 	3e. this.status = 'tracking';
 	3f. checks to see if tracking still happening by checking the width and height of the faceObj. if so, set headtrackerstatus and this.stop(); or faceFound = true;
 	3g. get headposition, intialize stable variable as status (false), then calculate headdiagonal **, set stable to true if conditions are met
 	3h. if stable and if it's the firstrun, create headposition object from headtracker.headposition.Tracker class with faceObj and canvas as parameters
 4. starter = function() -- safety checks before starting, keeps errors at bay
 5. this.start = function() -- runs starter() if video isn't running
 6. this.stop = function() -- stops everything! eee!
 7. fadeVideo fades the videoElement opacity out
 8. a mozilla bind shim**??**
 9. video support utility functions -- if supports x, runs canPlayType(x)
 10. headtrackr.ccv!! (viola-jones like face detection):
 	10a. grayscale -- gets context, getImageData from context (0, 0, canvas.width, canvas. height), gets imageData.data **??**; 
 	10b. array_group **??**
 	10c. detect_objects -- takes canvas, cascade (derived from the data for ccv), interval, and min_neighbors as arguments. It's called in doVJDetection() with arguments (headtrackr.ccv.grayscale(ccvCanvas), headtrackr.cascade, 5, 1); ccvCanvas == is a copy of the canvas (done to avoid interfence with camshift) which has been grayscaled and is a copy of the input canvas(video).
 	as far as I can tell, detect_objects creates an array based on the cascade width: -24, and height: 24; scale_upto tranlates to 27, next is 6, pyr becomes an array[156]
 	-pyr[0] = canvas, then does a lot of things with the pixel array, which is all in greyscale
 	
